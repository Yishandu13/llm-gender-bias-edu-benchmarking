# Benchmark work on llm-gender-implicit-bias-in-education
This repository is under construction and will be used for a benchmark study on "Do LLMs show gender bias when generating feedback for essay writing?"

The goal is to provide a scalable and reproducible framework for 
**auditing fairness in AI-powered writing support**
.
The whole structure of this repository (under construction) is:
```
.
├── data/                                   
│   ├── essay data/            # data of essay writing (original and counterfactual)
│       ├──original essay.xlsx   
│       └──essay-original and counterfactual.xlsx       
│   ├── gender/           # gender words used to construct counterfactual essays
│   ├── prompts/          
│       ├──prompt template.txt     # LLM prompt template used in this study
│       └──generated_prompts_demo.csv    # the demo prompts
│   ├── feedback to essays/             # response from LLMs
│       └──responses from llama.csv    # Here we provide feedback generated by LlaMA-3-8B as examples
│
├── data collection pipeline/  # GPT-5-mini, GPT-4o-mini, DeepSeek R1/Qwen, LLaMA-3-8B, Gemini 2.5 pro
│   ├── essay_counterfactal construction.py   # construct counterfactual gender essays
│   ├── construct_prompts.py             # construct prompts based on templates and raw data
│   ├── query_llms/                      # call llms with prompts
│       ├──gpt_openai.py                 # packaging OpenAI GPT-5-mini, GPT-4o-mini calls
│       ├──deepseek_api.py               # packaging DeepSeek-R1, DeepSeek-R-Qwen API calls
│       ├──Gemini_api.py                 # packaging Gemini-2.5-Pro API calls
│       └──llama_local.py                # local LLaMA model runs
│  
├── evaluation/                # analysis of feedback generated by llms
│   ├── embedding.py    
│   ├── similarity calculation.py    
│   └── visualisation and representative text extraction.py 
│
├── Main_Experiment_Gender_Bias_in_LLM_Generated_Essay_Feedback.ipynb      # Main experiment code
│
├── README.md
└── requirements.txt
```

## Getting started

### 1. Environment setup
Please have a Python environment ready.  
Install dependencies:
```bash
pip install -r requirements.txt
```
If you wish to execute the Jupyter notebook:
```bash
pip install ipykernel
```
### 2. Running the pipeline
• Counterfactual construction:
Run data collection pipeline/essay_counterfactual construction.py to generate counterfactual essays for implicit gender clues and use prompt template to provide explicit gender counterfactual clues.

• Prompt generation:
Run data collection pipeline/construct_prompts.py to prepare essay prompts for LLMs.

• LLM querying:
• Supply and save your OpenAI API key in the environment (or openai.key).
• For Gemini and DeepSeek APIs, configure credentials as per their documentation.
• For LLaMA, install and configure a local inference environment.
Example scripts can be found under data collection pipeline/query_llms/.

• Evaluation:
Use scripts under evaluation

You could directly run the Jupyter notebook "Main_Experiment_Gender_Bias_in_LLM_Generated_Essay_Feedback.ipynb" to reproduce the whole process and gain results.
