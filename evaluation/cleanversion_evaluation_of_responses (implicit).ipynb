{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Please upload evaluation file."
      ],
      "metadata": {
        "id": "TSAJeG8VRCbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9WZ2piWQS_Y"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Analysis of open ended feedback text.**\n",
        "### **1.1 similarity calculation (Cosine Similarity and Euclidean Distance)**"
      ],
      "metadata": {
        "id": "WB4yqSuNQcMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install openai pandas scipy numpy openpyxl tqdm matplotlib pingouin\n",
        "\n",
        "# Import required libraries\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cdist\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from getpass import getpass\n",
        "import pingouin as pg\n",
        "\n",
        "\n",
        "# Set OpenAI API Key\n",
        "openai_api_key = getpass(\"Enter your OpenAI API Key: \")\n",
        "\n",
        "\n",
        "# Function to retrieve text embeddings\n",
        "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
        "    response = openai.embeddings.create(\n",
        "        input=text,\n",
        "        model=model,\n",
        "        encoding_format=\"float\"\n",
        "    )\n",
        "    return np.array(response.data[0].embedding)\n",
        "\n",
        "\n",
        "# Load Excel file (assumes feedback for original and counterfactual essays are in the first and second columns)\n",
        "excel_path = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# Extract text columns\n",
        "texts_a = df.iloc[:, 0].astype(str).tolist()\n",
        "texts_b = df.iloc[:, 1].astype(str).tolist()\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings_a = np.array([get_embedding(text) for text in tqdm(texts_a, desc=\"Embedding A\")])\n",
        "embeddings_b = np.array([get_embedding(text) for text in tqdm(texts_b, desc=\"Embedding B\")])\n",
        "\n",
        "# Check the shape of the embedding matrices\n",
        "print(f\"embeddings_a shape: {embeddings_a.shape}\")  # Expected shape: (n_samples, embedding_dim)\n",
        "print(f\"embeddings_b shape: {embeddings_b.shape}\")\n",
        "\n",
        "\n",
        "# Compute pairwise similarity metrics\n",
        "def assess_similarity(matrix1, matrix2):\n",
        "    \"\"\"\n",
        "    Compute cosine similarity and Euclidean distance between aligned vectors.\n",
        "    Returns a DataFrame of results.\n",
        "    \"\"\"\n",
        "    cosine_sim = np.array([np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "                          for v1, v2 in zip(matrix1, matrix2)])\n",
        "\n",
        "    euclidean_dist = np.linalg.norm(matrix1 - matrix2, axis=1)\n",
        "\n",
        "    results = pd.DataFrame({\n",
        "        'cosine_similarity': cosine_sim,\n",
        "        'euclidean_distance': euclidean_dist\n",
        "    })\n",
        "    return results\n",
        "\n",
        "\n",
        "# Permutation testing and effect size calculation\n",
        "def permutation_test(matrix1, matrix2, n_permutations=5000, metric='cosine', seed=42):\n",
        "    np.random.seed(seed)\n",
        "    combined = np.vstack((matrix1, matrix2))\n",
        "    n = len(matrix1)\n",
        "\n",
        "    # Observed test statistic\n",
        "    obs_stat = np.mean(cdist(matrix1, matrix2, metric=metric))\n",
        "\n",
        "    # Permutation test\n",
        "    perm_stats = []\n",
        "    for _ in tqdm(range(n_permutations), desc=\"Permutations\"):\n",
        "        np.random.shuffle(combined)\n",
        "        perm_group1 = combined[:n]\n",
        "        perm_group2 = combined[n:]\n",
        "        perm_stat = np.mean(cdist(perm_group1, perm_group2, metric=metric))\n",
        "        perm_stats.append(perm_stat)\n",
        "\n",
        "    perm_stats = np.array(perm_stats)\n",
        "\n",
        "    # Two-tailed p-value\n",
        "    p_value = np.mean(np.abs(perm_stats - np.mean(perm_stats)) >= np.abs(obs_stat - np.mean(perm_stats)))\n",
        "\n",
        "    # Corrected effect size: avoid inflated values from low permutation variance\n",
        "    pooled_std = np.std(cdist(matrix1, matrix2, metric=metric))\n",
        "    effect_size_perm = (obs_stat - np.mean(perm_stats)) / pooled_std\n",
        "\n",
        "    # Additional effect size: Cohen's d\n",
        "    if metric == 'cosine':\n",
        "        # Convert similarity to distance for directional consistency with Euclidean\n",
        "        all_dists = 1 - np.array([np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "                         for v1 in matrix1 for v2 in matrix2])\n",
        "        within_dists = 1 - np.array([np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "                           for v1 in matrix1 for v2 in matrix1])\n",
        "    else:\n",
        "        all_dists = cdist(matrix1, matrix2, metric=metric).flatten()\n",
        "        within_dists = cdist(matrix1, matrix1, metric=metric).flatten()\n",
        "\n",
        "    cohen_d = pg.compute_effsize(all_dists, within_dists, eftype='cohen')\n",
        "\n",
        "    # Output results\n",
        "    print(\"\\n=== Permutation Test Results ===\")\n",
        "    print(f\"Metric: {metric}\")\n",
        "    print(f\"Observed Statistic: {obs_stat:.4f}\")\n",
        "    print(f\"Permutation Mean: {np.mean(perm_stats):.4f}\")\n",
        "    print(f\"p-value (two-tailed): {p_value:.4f}\")\n",
        "    print(f\"Effect Size (Corrected Z): {effect_size_perm:.4f}\")\n",
        "    print(f\"Cohen's d (between vs within): {cohen_d:.4f}\")\n",
        "\n",
        "    # Plot permutation distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(perm_stats, bins=50, alpha=0.7, label='Permutation Distribution')\n",
        "    plt.axvline(obs_stat, color='red', linestyle='--', linewidth=2, label='Observed')\n",
        "    plt.axvline(np.mean(perm_stats), color='green', linestyle=':', linewidth=2, label='Perm Mean')\n",
        "    plt.legend()\n",
        "    plt.title(f\"Permutation Test: {metric} (n_perm={n_permutations})\")\n",
        "    plt.xlabel(\"Distance\" if metric != 'cosine' else \"1 - Cosine Similarity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'observed_stat': obs_stat,\n",
        "        'p_value': p_value,\n",
        "        'effect_size_perm': effect_size_perm,\n",
        "        'cohen_d': cohen_d\n",
        "    }\n",
        "\n",
        "\n",
        "# Main analysis pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Compute descriptive similarity metrics\n",
        "    similarity_results = assess_similarity(embeddings_a, embeddings_b)\n",
        "    print(\"\\n=== Descriptive Statistics ===\")\n",
        "    print(similarity_results.describe())\n",
        "\n",
        "    # 2. Plot similarity and distance distributions\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(similarity_results['cosine_similarity'], bins=30, alpha=0.7)\n",
        "    plt.title(\"Cosine Similarity Distribution\")\n",
        "    plt.xlabel(\"Similarity\")\n",
        "    plt.ylabel(\"Count\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(similarity_results['euclidean_distance'], bins=30, alpha=0.7, color='orange')\n",
        "    plt.title(\"Euclidean Distance Distribution\")\n",
        "    plt.xlabel(\"Distance\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Run permutation test on cosine similarity\n",
        "    print(\"\\nRunning Cosine Similarity Analysis...\")\n",
        "    cos_result = permutation_test(embeddings_a, embeddings_b, metric='cosine')\n",
        "\n",
        "    # 4. Run permutation test on Euclidean distance\n",
        "    print(\"\\nRunning Euclidean Distance Analysis...\")\n",
        "    euc_result = permutation_test(embeddings_a, embeddings_b, metric='euclidean')"
      ],
      "metadata": {
        "id": "gQN1KMXBSW4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes on Statistical Methodology**\n",
        "\n",
        "1.Effect Size\n",
        "\n",
        "In initial analyses, the observed cosine similarity (mean = 0.1876) showed a marginal deviation from the permutation mean (0.1800). When using the standard deviation of the permutation distribution as the denominator, this small absolute difference yielded an inflated effect size (>90), indicating oversensitivity to minimal fluctuations in the null distribution.  \n",
        "\n",
        "To address this, this analysis substituted the denominator with the pooled standard deviation of the empirical (non-permuted) distances:  \n",
        "\n",
        "`pooled_std = np.std(cdist(matrix1, matrix2, metric=metric))`\n",
        "\n",
        "This correction yields a stabilized permutation Z-score that better reflects the true effect magnitude. Cohen's d is reported as a complementary reference metric for effect size interpretation.\n",
        "\n",
        "\n",
        "2.Direction Consistency in Metrics\n",
        "\n",
        "Since cosine similarity increases with semantic similarity (higher = more similar), while Euclidean distance decreases (lower = more similar), I convert cosine similarity to a distance-like metric:\n",
        "\n",
        "`distance = 1 - cosine_similarity`\n",
        "\n",
        "to ensure interpretative consistency across metrics (i.e., lower values always indicate more similarity).\n",
        "\n",
        "\n",
        "\n",
        "3.Permutation Testing\n",
        "\n",
        "A two-tailed p-value is computed in this analysis, comparing the observed statistic to the full permutation distribution.\n",
        "\n",
        "This nonparametric test avoids assumptions about normality and enables robust inference from embedding distances."
      ],
      "metadata": {
        "id": "3Tk2lcTjUpbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Visualization through dimensionality reduction**\n",
        "The implementation includes:\n",
        "\n",
        "\n",
        "PCA Analysis: Evaluates global structure preservation through explained variance and reconstruction error, identifying dominant directions of variation in the embedding space.\n",
        "\n",
        "t-SNE Projection: Assesses local neighborhood preservation using trustworthiness and k-NN preservation metrics, particularly valuable for identifying cluster separation and local structure.\n",
        "\n",
        "UMAP Visualization: Offers an alternative nonlinear projection with quantitative evaluation of local structure maintenance through k-NN preservation rates.\n",
        "\n",
        "Dot Product Analysis: Provides direct measurement of semantic alignment between\n",
        "paired embeddings, with statistical characterization of similarity distribution."
      ],
      "metadata": {
        "id": "S0Fd8mijT4Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn\n",
        "import umap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.manifold import trustworthiness\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def analyze_and_visualize_embeddings(embeddings_a, embeddings_b, labels=('Original', 'Counterfactual')):\n",
        "    \"\"\"\n",
        "    Perform dimensionality reduction and comparative analysis of two sets of embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings_a (np.array): First set of embeddings (n_samples x n_features)\n",
        "        embeddings_b (np.array): Second set of embeddings (n_samples x n_features)\n",
        "        labels (tuple): Descriptive labels for the two groups\n",
        "    \"\"\"\n",
        "    combined = np.vstack((embeddings_a, embeddings_b))\n",
        "    group_labels = [labels[0]] * len(embeddings_a) + [labels[1]] * len(embeddings_b)\n",
        "\n",
        "    # PCA Dimensionality Reduction\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced_pca = pca.fit_transform(combined)\n",
        "\n",
        "    df_pca = pd.DataFrame({\n",
        "        'Dim1': reduced_pca[:, 0],\n",
        "        'Dim2': reduced_pca[:, 1],\n",
        "        'Group': group_labels\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    palette = {labels[0]: 'blue', labels[1]: 'red'}\n",
        "    sns.scatterplot(data=df_pca, x='Dim1', y='Dim2', hue='Group', palette=palette)\n",
        "    plt.title(\"PCA: Principal Component Analysis (2D Projection)\")\n",
        "    plt.xlabel(\"Principal Component 1\")\n",
        "    plt.ylabel(\"Principal Component 2\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # PCA diagnostic metrics\n",
        "    explained_var = pca.explained_variance_ratio_\n",
        "    eigenvalues = pca.explained_variance_\n",
        "    projected = pca.inverse_transform(reduced_pca)\n",
        "    reconstruction_error = mean_squared_error(combined, projected)\n",
        "\n",
        "    print(\"PCA Diagnostic Metrics:\")\n",
        "    print(f\"- Eigenvalues: {eigenvalues}\")\n",
        "    print(f\"- Explained Variance Ratio: {explained_var}\")\n",
        "    print(f\"- Cumulative Explained Variance: {np.sum(explained_var):.4f}\")\n",
        "    print(f\"- Reconstruction MSE: {reconstruction_error:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    Eigenvalues indicate the magnitude of variance captured by each principal component.\n",
        "    Explained variance ratios show the proportion of total variance accounted for by each component.\n",
        "    Reconstruction error measures information loss during dimensionality reduction.\\n\"\"\")\n",
        "\n",
        "    # t-SNE Visualization\n",
        "    tsne = TSNE(n_components=2, perplexity=30, random_state=42, init='pca')\n",
        "    reduced_tsne = tsne.fit_transform(combined)\n",
        "\n",
        "    df_tsne = pd.DataFrame({\n",
        "        'x': reduced_tsne[:, 0],\n",
        "        'y': reduced_tsne[:, 1],\n",
        "        'Group': group_labels\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(data=df_tsne, x='x', y='y', hue='Group', palette=palette)\n",
        "    plt.title(\"t-SNE: t-distributed Stochastic Neighbor Embedding\")\n",
        "    plt.xlabel(\"t-SNE Dimension 1\")\n",
        "    plt.ylabel(\"t-SNE Dimension 2\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # t-SNE quality metrics\n",
        "    trust = trustworthiness(combined, reduced_tsne, n_neighbors=5)\n",
        "\n",
        "    # k-NN preservation calculation\n",
        "    knn_original = NearestNeighbors(n_neighbors=5).fit(combined).kneighbors(return_distance=False)\n",
        "    knn_embedded = NearestNeighbors(n_neighbors=5).fit(reduced_tsne).kneighbors(return_distance=False)\n",
        "    preserved = np.mean([\n",
        "        len(np.intersect1d(knn_original[i], knn_embedded[i])) / 5.0\n",
        "        for i in range(len(combined))\n",
        "    ])\n",
        "\n",
        "    print(\"t-SNE Quality Metrics:\")\n",
        "    print(f\"- KL Divergence: {tsne.kl_divergence_:.4f}\")\n",
        "    print(f\"- Trustworthiness: {trust:.4f}\")\n",
        "    print(f\"- k-NN Preservation Rate: {preserved:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    KL divergence quantifies the difference between high-dimensional and low-dimensional distributions.\n",
        "    Trustworthiness measures the preservation of neighborhood relationships (higher is better).\n",
        "    k-NN preservation rate indicates local structure maintenance during dimensionality reduction.\\n\"\"\")\n",
        "\n",
        "    # UMAP Projection\n",
        "    reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean', random_state=42)\n",
        "    reduced_umap = reducer.fit_transform(combined)\n",
        "\n",
        "    df_umap = pd.DataFrame({\n",
        "        'x': reduced_umap[:, 0],\n",
        "        'y': reduced_umap[:, 1],\n",
        "        'Group': group_labels\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(data=df_umap, x='x', y='y', hue='Group', palette=palette)\n",
        "    plt.title(\"UMAP: Uniform Manifold Approximation and Projection\")\n",
        "    plt.xlabel(\"UMAP Dimension 1\")\n",
        "    plt.ylabel(\"UMAP Dimension 2\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # UMAP quality assessment\n",
        "    knn_embedded_umap = NearestNeighbors(n_neighbors=5).fit(reduced_umap).kneighbors(return_distance=False)\n",
        "    preserved_umap = np.mean([\n",
        "        len(np.intersect1d(knn_original[i], knn_embedded_umap[i])) / 5.0\n",
        "        for i in range(len(combined))\n",
        "    ])\n",
        "\n",
        "    print(\"UMAP Quality Metrics:\")\n",
        "    print(f\"- k-NN Preservation Rate: {preserved_umap:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    The k-NN preservation rate quantifies how well UMAP maintains local neighborhood structures\n",
        "    from the original high-dimensional space in the 2D projection.\\n\"\"\")\n",
        "\n",
        "    # Dot Product Analysis\n",
        "    dot_products = np.sum(embeddings_a * embeddings_b, axis=1)\n",
        "    mean_dot = np.mean(dot_products)\n",
        "    std_dot = np.std(dot_products)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(dot_products, bins=30, color='skyblue', alpha=0.7)\n",
        "    plt.axvline(mean_dot, color='red', linestyle='--', label=f\"Mean: {mean_dot:.4f}\")\n",
        "    plt.title(\"Dot Product Distribution Between Paired Embeddings\")\n",
        "    plt.xlabel(\"Dot Product Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Dot Product Statistics:\")\n",
        "    print(f\"- Mean: {mean_dot:.4f}\")\n",
        "    print(f\"- Standard Deviation: {std_dot:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    Dot products measure the alignment between corresponding embedding vectors.\n",
        "    Higher values indicate greater semantic similarity between paired samples.\n",
        "    The standard deviation reflects the consistency of similarity across pairs.\\n\"\"\")\n",
        "\n",
        "# Example execution\n",
        "analyze_and_visualize_embeddings(embeddings_a, embeddings_b)"
      ],
      "metadata": {
        "id": "_RCTWFONTgB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Other Comparative Analyses**\n",
        " This part integrates centroid distance metrics to assess global vector space shifts, clustering performance to evaluate separability, linguistic statistics for content-level insights, and graph-based visualization to reveal interaction structures in semantic space."
      ],
      "metadata": {
        "id": "omABUmDkbQfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "\n",
        "'''\n",
        "Assumes the following variables are already loaded:\n",
        "- embeddings_a, embeddings_b: numpy arrays of shape (n_samples, n_features)\n",
        "- texts_a, texts_b: lists of strings associated with each embedding\n",
        "'''\n",
        "\n",
        "# Group Centroid Distance Analysis\n",
        "\n",
        "# Compute the mean embedding (centroid) of each group\n",
        "centroid_a = np.mean(embeddings_a, axis=0)\n",
        "centroid_b = np.mean(embeddings_b, axis=0)\n",
        "\n",
        "# Measure distance between group centroids using both Euclidean and cosine metrics\n",
        "euclidean_distance = np.linalg.norm(centroid_a - centroid_b)\n",
        "cosine_dist = cosine(centroid_a, centroid_b)\n",
        "\n",
        "print(\"Group Centroid Distance:\")\n",
        "print(f\"- Euclidean Distance-group: {euclidean_distance:.4f}\")\n",
        "print(f\"- Cosine Distance-group: {cosine_dist:.4f}\\n\")\n",
        "print(\"Euclidean distance reflects spatial divergence between group centers, while cosine distance quantifies semantic angle difference (1 = orthogonal, 0 = identical).\\n\")\n",
        "\n",
        "'''\n",
        "Group Centroid Distance complements pairwise similarity analysis by capturing overall semantic drift between groups,\n",
        "whereas pairwise cosine/Euclidean distances in 1.1 reflect local alignment of text pairs.\n",
        "'''\n",
        "\n",
        "# KMeans Clustering and Text Feature Analysis\n",
        "\n",
        "# Combine embeddings and texts for unified analysis\n",
        "combined_embeddings = np.vstack((embeddings_a, embeddings_b))\n",
        "combined_texts = texts_a + texts_b\n",
        "\n",
        "# Apply KMeans clustering to identify potential separable groups\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=\"auto\")\n",
        "cluster_labels = kmeans.fit_predict(combined_embeddings)\n",
        "sil_score = silhouette_score(combined_embeddings, cluster_labels)\n",
        "\n",
        "print(\"KMeans Clustering:\")\n",
        "print(f\"- Silhouette Score: {sil_score:.4f}\\n\")\n",
        "print(\"Silhouette score quantifies cluster quality; values closer to 1 indicate well-separated dense clusters.\\n\")\n",
        "\n",
        "# Calculate text-level features: length and type-token ratio (TTR)\n",
        "lengths = [len(text.split()) for text in combined_texts]\n",
        "ttrs = [len(set(text.split())) / len(text.split()) if len(text.split()) > 0 else 0 for text in combined_texts]\n",
        "\n",
        "print(\"Text Feature Analysis:\")\n",
        "print(f\"- Avg. Text Length: {np.mean(lengths):.2f} Â± {np.std(lengths):.2f}\")\n",
        "print(f\"- Avg. Type-Token Ratio: {np.mean(ttrs):.4f} Â± {np.std(ttrs):.4f}\\n\")\n",
        "\n",
        "# Plot distribution of text lengths\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(lengths, kde=True, color='skyblue')\n",
        "plt.title(\"Distribution of Text Lengths\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot distribution of type-token ratios\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(ttrs, kde=True, color='salmon')\n",
        "plt.title(\"Type-Token Ratio (TTR) Distribution\")\n",
        "plt.xlabel(\"TTR\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"These visualizations reveal lexical variation and verbosity patterns across both groups. TTR indicates vocabulary diversity; higher TTR suggests more unique word usage.\\n\")\n",
        "\n",
        "\n",
        "# Semantic Interaction Network via Cosine Similarity\n",
        "\n",
        "# Compute cosine similarity matrix for all texts\n",
        "similarity_matrix = cosine_similarity(combined_embeddings)\n",
        "\n",
        "# Construct undirected graph: nodes = texts, edges = high-similarity links\n",
        "G = nx.Graph()\n",
        "for i in range(len(combined_texts)):\n",
        "    G.add_node(i, label=i, group='A' if i < len(embeddings_a) else 'B')\n",
        "\n",
        "# Add edges for text pairs with similarity above a threshold\n",
        "threshold = 0.85  # similarity cutoff for connection\n",
        "for i in range(len(similarity_matrix)):\n",
        "    for j in range(i + 1, len(similarity_matrix)):\n",
        "        sim = similarity_matrix[i][j]\n",
        "        if sim >= threshold:\n",
        "            G.add_edge(i, j, weight=sim)\n",
        "\n",
        "# Layout nodes in 2D using spring layout (force-directed)\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "colors = ['blue' if G.nodes[n]['group'] == 'A' else 'red' for n in G.nodes]\n",
        "\n",
        "# Visualize the similarity network\n",
        "plt.figure(figsize=(12, 9))\n",
        "nx.draw(G, pos, with_labels=True, node_color=colors, node_size=600, font_size=9, edge_color='gray', alpha=0.8)\n",
        "plt.title(\"ðŸ”— Text Similarity Network (Cosine â‰¥ 0.85)\")\n",
        "plt.show()\n",
        "\n",
        "# Report network-level statistics\n",
        "print(\"ðŸ“¡ Graph Summary:\")\n",
        "print(f\"- Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}\")\n",
        "degree_dist = [d for _, d in G.degree()]\n",
        "print(f\"- Avg. Degree: {np.mean(degree_dist):.2f}, Max Degree: {np.max(degree_dist)}\")\n",
        "\n",
        "print(\"This similarity graph reveals clusters of highly similar texts and the degree of interaction within and across groups. Degree centrality reflects semantic \"hubness\" â€” texts with high degrees are more semantically connected.\")\n"
      ],
      "metadata": {
        "id": "zAzIVucVXFYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Analysis of scores' value to essays.**"
      ],
      "metadata": {
        "id": "OUty2KQ6b-Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract score from responses.\n",
        "Group A contains scores for original essays and Group B contains those for counterfactual essays."
      ],
      "metadata": {
        "id": "TpX5NOJYdFiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# extract score from responses\n",
        "def extract_score(text):\n",
        "    patterns = [\n",
        "        r'\\*\\*(\\d[\\d.]*)\\*\\*',  # **4** or **4.5**\n",
        "        r'Score:\\s*([\\d.]+)',    # \"Score: 3\" or \"Score: 4.5\"\n",
        "        r'^(\\d[\\d.]*)\\s*$',      #  \"3\" or \"4.5\"\n",
        "        r'(\\d[\\d.]*)\\s*out of 5',#  \"4 out of 5\"\n",
        "        r'(\\d[\\d.]*)/5',         #  \"4/5\"\n",
        "        r'^(\\d[\\d.]*)\\s*[-:]',   #  \"4 -\" or \"4:\"\n",
        "        r'\\b(\\d[\\d.]*)\\s*$'      # Match the fraction at the end of the line\n",
        "    ]\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "    first_line = text.split('\\n')[0].strip()\n",
        "    if re.match(r'^\\d[\\d.]*$', first_line):\n",
        "        return float(first_line)\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
        "        if match:\n",
        "            try:\n",
        "                score = float(match.group(1))\n",
        "                if 0 <= score <= 5:\n",
        "                    return score\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def extract_scores_no_header(input_path, output_path):\n",
        "    df = pd.read_excel(input_path, header=None)\n",
        "    df.columns = ['group a', 'group b']\n",
        "\n",
        "    df['group a score'] = df['group a'].apply(extract_score)\n",
        "    df['group b score'] = df['group b'].apply(extract_score)\n",
        "\n",
        "    score_df = df[['group a score', 'group b score']]\n",
        "    score_df.to_excel(output_path, index=False)\n",
        "    print(\"Score extraction is complete and has been saved as:\", output_path)\n",
        "\n",
        "extract_scores_no_header(\n",
        "    input_path='/content/cosine similarity calculationM vs M-F.xlsx',\n",
        "    output_path='/content/extracted_scores_only.xlsx'\n",
        ")"
      ],
      "metadata": {
        "id": "i0Y2JozgcF5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score\n",
        "\n",
        "df = pd.read_excel(\"/content/extracted_scores_only.xlsx\")\n",
        "a_scores = df['group a score']\n",
        "b_scores = df['group b score']\n",
        "\n",
        "# Descriptive Statistics\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 2ï¸Paired t-test\n",
        "t_stat, p_val = ttest_rel(a_scores, b_scores)\n",
        "print(f\"\\nPaired t-test:\\nt = {t_stat:.4f}, p = {p_val:.4f}\")\n",
        "if p_val < 0.05:\n",
        "    print(\"â†’ significant difference\")\n",
        "else:\n",
        "    print(\"â†’ no significant difference\")\n",
        "\n",
        "#Box Plot + Density Plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=df, palette=\"Set2\")\n",
        "plt.title(\"Boxplot of Scores\")\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(a_scores, label='Group A', fill=True)\n",
        "sns.kdeplot(b_scores, label='Group B', fill=True)\n",
        "plt.title(\"Density Plot of Scores\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Scatterplot + Line of Fit\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.regplot(x=a_scores, y=b_scores, ci=None, scatter_kws={\"s\": 50})\n",
        "plt.plot([0, 5], [0, 5], 'r--', label=\"Perfect Agreement\")\n",
        "plt.xlabel(\"Group A Score\")\n",
        "plt.ylabel(\"Group B Score\")\n",
        "plt.title(\"Scatter Plot with Fit Line\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# confusion matrix\n",
        "'''\n",
        "a_int = a_scores.round().astype(int)\n",
        "b_int = b_scores.round().astype(int)\n",
        "conf_mat = confusion_matrix(a_int, b_int, labels=[1,2,3,4,5])\n",
        "disp = ConfusionMatrixDisplay(conf_mat, display_labels=[1,2,3,4,5])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Rounded Scores)\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "'''\n",
        "bins = [1.9, 2.25, 2.75, 3.25, 3.75, 4.25]  # Define split-box boundaries, could be set according to the actual scoring interval\n",
        "labels = ['2', '2.5', '3', '3.5', '4']\n",
        "\n",
        "a_cat = pd.cut(a_scores, bins=bins, labels=labels, right=False)\n",
        "b_cat = pd.cut(b_scores, bins=bins, labels=labels, right=False)\n",
        "\n",
        "conf_mat = confusion_matrix(a_cat, b_cat, labels=labels)\n",
        "disp = ConfusionMatrixDisplay(conf_mat, display_labels=labels)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix (Precise 0.5-point Scale)\\nGroup A=True, Group B=Predicted\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "# è®¡ç®—åˆ†ç±»æŠ¥å‘Š\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nCategorized reports (Taking Group A as real labels, Group B for predicted labels):\")\n",
        "print(classification_report(a_cat, b_cat, target_names=labels, zero_division=0))\n",
        "\n",
        "# Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(a_cat, b_cat)\n",
        "print(f\"\\nCohenâ€™s Kappa Score (0.5-point scale): {kappa:.3f}\")\n",
        "if kappa < 0.2:\n",
        "    level = \"Almost no consistency\"\n",
        "elif kappa < 0.4:\n",
        "    level = \"Less consistency\"\n",
        "elif kappa < 0.6:\n",
        "    level = \"Medium consistency\"\n",
        "elif kappa < 0.8:\n",
        "    level = \"Good consistency\"\n",
        "else:\n",
        "    level = \"Almost perfect consistency\"\n",
        "print(f\"â†’ Consistency level: {level}\")\n",
        "\n",
        "# score difference\n",
        "df['score_diff'] = b_scores - a_scores\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df['score_diff'], bins=10, kde=True)\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(\"Distribution of Score Differences (B - A)\")\n",
        "plt.xlabel(\"Score Difference\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAnalysis of variances by specific scores:\")\n",
        "score_levels = sorted(df['group a score'].unique())\n",
        "for score in score_levels:\n",
        "    subset = df[df['group a score'] == score]\n",
        "    mean_diff = subset['score_diff'].mean()\n",
        "    count = len(subset)\n",
        "    print(f\"When Group A is {score:.1f}ï¼ˆn={count}ï¼‰:\")\n",
        "    print(f\"  â†’ Group B average difference: {mean_diff:.3f}\")\n",
        "    print(f\"  â†’ Group B scoring distribution: {subset['group b score'].value_counts().sort_index().to_dict()}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for score in sorted(df['group a score'].unique()):\n",
        "    subset = df[df['group a score'] == score]\n",
        "    sns.kdeplot(subset['score_diff'], label=f'A={score}', fill=True)\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.title(\"Distribution of Score Differences (B - A) by Original Score\")\n",
        "plt.xlabel(\"Score Difference\")\n",
        "plt.legend(title=\"Group A Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Statistics on the direction of change in scores\n",
        "df['direction'] = np.where(df['score_diff'] > 0, 'Increase',\n",
        "                          np.where(df['score_diff'] < 0, 'Decrease', 'No change'))\n",
        "direction_counts = df['direction'].value_counts()\n",
        "print(\"\\nStatistics on the direction of change in scores:\")\n",
        "print(direction_counts)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=direction_counts.index, y=direction_counts.values, palette=\"viridis\")\n",
        "plt.title(\"Score Change Direction (Group B vs Group A)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "mean_diff = df['score_diff'].mean()\n",
        "print(f\"\\nDifference in average ratingsï¼ˆGroup B - Group Aï¼‰: {mean_diff:.3f}\")"
      ],
      "metadata": {
        "id": "-nLACkGJdJhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
