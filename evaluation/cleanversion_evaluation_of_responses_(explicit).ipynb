{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "cosine similarity calculate\n",
        "Gender-related school context, student’s name, and pronoun are integrated in prompts, including **male clues (Group A)**, **female clues (Group B)**, and **neutral-gender clues (Group C)**."
      ],
      "metadata": {
        "id": "l0ld00udFQ7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUdHs3bME8U4"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install openai pandas scipy numpy openpyxl tqdm matplotlib pingouin statsmodels seaborn\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cdist, pdist, squareform\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pingouin as pg\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from itertools import combinations\n",
        "\n",
        "# upload embeddings\n",
        "# Load three groups of embeddings\n",
        "embeddings_a = np.load(\"embeddings_a.npy\")\n",
        "embeddings_b = np.load(\"embeddings_b.npy\")\n",
        "embeddings_c = np.load(\"embeddings_c.npy\")\n",
        "\n",
        "# Check shapes\n",
        "print(f\"Group A shape: {embeddings_a.shape}\")\n",
        "print(f\"Group B shape: {embeddings_b.shape}\")\n",
        "print(f\"Group C shape: {embeddings_c.shape}\")\n",
        "\n",
        "# ============================================\n",
        "# 1. Pairwise Similarity Assessment\n",
        "# ============================================\n",
        "def assess_similarity(matrix1, matrix2):\n",
        "    \"\"\"Compute cosine similarity and Euclidean distance between aligned vectors\"\"\"\n",
        "    cosine_sim = np.array([np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "                      for v1,v2 in zip(matrix1, matrix2)])\n",
        "    euclidean_dist = np.linalg.norm(matrix1 - matrix2, axis=1)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'cosine_similarity': cosine_sim,\n",
        "        'euclidean_distance': euclidean_dist\n",
        "    })\n",
        "\n",
        "# ============================================\n",
        "# 2. Enhanced Permutation Test with Original Plots\n",
        "# ============================================\n",
        "def permutation_test(groups, group_names, n_permutations=5000, metric='cosine', seed=42):\n",
        "    \"\"\"\n",
        "    Perform permutation testing between multiple groups with original visualization\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    n_groups = len(groups)\n",
        "    combined = np.vstack(groups)\n",
        "    group_sizes = [len(g) for g in groups]\n",
        "\n",
        "    # Store all permutation distributions for plotting\n",
        "    full_perm_stats = {}\n",
        "\n",
        "    # Observed statistics and pairwise results\n",
        "    observed_stats = {}\n",
        "    pairwise_results = {}\n",
        "\n",
        "    for i in range(n_groups):\n",
        "        for j in range(i+1, n_groups):\n",
        "            key = f\"{group_names[i]}-{group_names[j]}\"\n",
        "\n",
        "            # Original permutation test logic for each pair\n",
        "            obs_stat = np.mean(cdist(groups[i], groups[j], metric=metric))\n",
        "            perm_stats = []\n",
        "\n",
        "            for _ in range(n_permutations):\n",
        "                perm_indices = np.random.permutation(len(combined))\n",
        "                perm_group1 = combined[perm_indices[:group_sizes[i]]]\n",
        "                perm_group2 = combined[perm_indices[group_sizes[i]:group_sizes[i]+group_sizes[j]]]\n",
        "                perm_stats.append(np.mean(cdist(perm_group1, perm_group2, metric=metric)))\n",
        "\n",
        "            perm_stats = np.array(perm_stats)\n",
        "            full_perm_stats[key] = perm_stats\n",
        "\n",
        "            # Calculate statistics\n",
        "            p_value = np.mean(np.abs(perm_stats - np.mean(perm_stats)) >= np.abs(obs_stat - np.mean(perm_stats)))\n",
        "            pooled_std = np.std(cdist(groups[i], groups[j], metric=metric))\n",
        "            effect_size = (obs_stat - np.mean(perm_stats)) / pooled_std\n",
        "\n",
        "            # Cohen's d calculation\n",
        "            if metric == 'cosine':\n",
        "                all_dists = 1 - cosine_similarity(groups[i], groups[j]).flatten()\n",
        "                within_dists = []\n",
        "                for g in [i, j]:\n",
        "                    within_dists.extend(1 - cosine_similarity(groups[g]).flatten())\n",
        "            else:\n",
        "                all_dists = cdist(groups[i], groups[j], metric=metric).flatten()\n",
        "                within_dists = []\n",
        "                for g in [i, j]:\n",
        "                    within_dists.extend(squareform(pdist(groups[g], metric=metric)).flatten())\n",
        "\n",
        "            cohen_d = pg.compute_effsize(all_dists, within_dists, eftype='cohen')\n",
        "\n",
        "            # Store results\n",
        "            observed_stats[key] = obs_stat\n",
        "            pairwise_results[key] = {\n",
        "                'observed': obs_stat,\n",
        "                'perm_mean': np.mean(perm_stats),\n",
        "                'p_value': p_value,\n",
        "                'effect_size': effect_size,\n",
        "                'cohen_d': cohen_d,\n",
        "                'perm_dist': perm_stats\n",
        "            }\n",
        "\n",
        "            # Print results for each pair\n",
        "            print(f\"\\n=== {group_names[i]} vs {group_names[j]} ({metric}) ===\")\n",
        "            print(f\"Observed Statistic: {obs_stat:.4f}\")\n",
        "            print(f\"Permutation Mean: {np.mean(perm_stats):.4f}\")\n",
        "            print(f\"p-value (two-tailed): {p_value:.4f}\")\n",
        "            print(f\"Effect Size (Corrected Z): {effect_size:.4f}\")\n",
        "            print(f\"Cohen's d (between vs within): {cohen_d:.4f}\")\n",
        "\n",
        "            # Plot permutation distribution\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.hist(perm_stats, bins=50, alpha=0.7, label='Permutation Distribution')\n",
        "            plt.axvline(obs_stat, color='red', linestyle='--', linewidth=2, label='Observed')\n",
        "            plt.axvline(np.mean(perm_stats), color='green', linestyle=':', linewidth=2, label='Perm Mean')\n",
        "            plt.legend()\n",
        "            plt.title(f\"Permutation Test: {group_names[i]} vs {group_names[j]} ({metric}, n_perm={n_permutations})\")\n",
        "            plt.xlabel(\"Distance\" if metric != 'cosine' else \"1 - Cosine Similarity\")\n",
        "            plt.ylabel(\"Frequency\")\n",
        "            plt.show()\n",
        "\n",
        "    return {\n",
        "        'observed_stats': observed_stats,\n",
        "        'pairwise_results': pairwise_results,\n",
        "        'full_perm_stats': full_perm_stats\n",
        "    }\n",
        "\n",
        "# ============================================\n",
        "# 3. Enhanced Visualization Functions\n",
        "# ============================================\n",
        "def plot_similarity_distributions(groups, group_names):\n",
        "    \"\"\"Plot similarity/distance distributions for all pairs\"\"\"\n",
        "    # Create all pairwise combinations\n",
        "    pairs = [(i,j) for i in range(len(groups)) for j in range(i+1, len(groups))]\n",
        "\n",
        "    for metric in ['cosine', 'euclidean']:\n",
        "        plt.figure(figsize=(15, 5*len(pairs)))\n",
        "        for idx, (i,j) in enumerate(pairs, 1):\n",
        "            # Compute similarities\n",
        "            if metric == 'cosine':\n",
        "                values = cosine_similarity(groups[i], groups[j]).diagonal()\n",
        "                xlabel = \"Cosine Similarity\"\n",
        "            else:\n",
        "                values = np.linalg.norm(groups[i] - groups[j], axis=1)\n",
        "                xlabel = \"Euclidean Distance\"\n",
        "\n",
        "            # Plot\n",
        "            plt.subplot(len(pairs), 2, 2*idx-1)\n",
        "            sns.histplot(values, bins=30, kde=True)\n",
        "            plt.title(f\"{group_names[i]} vs {group_names[j]} {xlabel} Distribution\")\n",
        "            plt.xlabel(xlabel)\n",
        "\n",
        "            plt.subplot(len(pairs), 2, 2*idx)\n",
        "            sns.boxplot(x=values)\n",
        "            plt.title(f\"{group_names[i]} vs {group_names[j]} {xlabel} Spread\")\n",
        "            plt.xlabel(xlabel)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_multi_group_comparison(results_dict, metric):\n",
        "    \"\"\"Visualize all pairwise comparisons together\"\"\"\n",
        "    comparisons = []\n",
        "    obs_values = []\n",
        "    p_values = []\n",
        "    effect_sizes = []\n",
        "\n",
        "    for key, res in results_dict['pairwise_results'].items():\n",
        "        comparisons.append(key)\n",
        "        obs_values.append(res['observed'])\n",
        "        p_values.append(res['p_value'])\n",
        "        effect_sizes.append(res['effect_size'])\n",
        "\n",
        "    # Create figure\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Plot observed statistics\n",
        "    sns.barplot(x=comparisons, y=obs_values, ax=ax1, palette=\"viridis\")\n",
        "    ax1.set_title(f\"Observed {metric} Statistics\")\n",
        "    ax1.set_ylabel(\"Mean Distance\" if metric == 'euclidean' else \"1 - Mean Cosine Similarity\")\n",
        "\n",
        "    # Plot effect sizes\n",
        "    sns.barplot(x=comparisons, y=effect_sizes, ax=ax2, palette=\"magma\")\n",
        "    ax2.axhline(0.2, color='red', linestyle='--', alpha=0.5, label='Small effect')\n",
        "    ax2.axhline(0.5, color='red', linestyle=':', alpha=0.5, label='Medium effect')\n",
        "    ax2.set_title(f\"Effect Sizes ({metric})\")\n",
        "    ax2.set_ylabel(\"Corrected Z-score Effect Size\")\n",
        "    ax2.legend()\n",
        "\n",
        "    # Add significance markers\n",
        "    y_max = max(obs_values) * 1.1\n",
        "    for i, pval in enumerate(p_values):\n",
        "        if pval < 0.05:\n",
        "            ax1.text(i, y_max, \"*\" if pval < 0.05 else \"**\" if pval < 0.01 else \"***\",\n",
        "                    ha='center', va='bottom', color='red', fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================\n",
        "# 4. Main Analysis Pipeline\n",
        "# ============================================\n",
        "if __name__ == \"__main__\":\n",
        "    groups = [embeddings_a, embeddings_b, embeddings_c]\n",
        "    group_names = ['A', 'B', 'C']\n",
        "\n",
        "    # 1. Pairwise distribution visualization\n",
        "    print(\"\\n=== Pairwise Distribution Visualizations ===\")\n",
        "    plot_similarity_distributions(groups, group_names)\n",
        "\n",
        "    # 2. Calculate and print descriptive statistics for all pairs\n",
        "    print(\"\\n=== Pairwise Descriptive Statistics ===\")\n",
        "    for i in range(len(groups)):\n",
        "        for j in range(i+1, len(groups)):\n",
        "            print(f\"\\nGroup {group_names[i]} vs Group {group_names[j]}:\")\n",
        "            sim_results = assess_similarity(groups[i], groups[j])\n",
        "            desc = sim_results.describe()\n",
        "            for col in sim_results.columns:\n",
        "                print(f\"\\n--- {col.replace('_', ' ').title()} ---\")\n",
        "                print(desc[col].to_string(float_format=\"%.4f\"))\n",
        "\n",
        "    # 3. Run permutation tests\n",
        "    print(\"\\n=== Cosine Similarity Analysis ===\")\n",
        "    cos_results = permutation_test(groups, group_names, metric='cosine')\n",
        "    plot_multi_group_comparison(cos_results, 'cosine')\n",
        "\n",
        "    print(\"\\n=== Euclidean Distance Analysis ===\")\n",
        "    euc_results = permutation_test(groups, group_names, metric='euclidean')\n",
        "    plot_multi_group_comparison(euc_results, 'euclidean')\n",
        "\n",
        "    # 4. ANOVA and post-hoc tests\n",
        "    print(\"\\n=== ANOVA Results ===\")\n",
        "    for metric in ['cosine', 'euclidean']:\n",
        "        # Prepare data (convert similarities to distances for consistency)\n",
        "        data = []\n",
        "        for i in range(len(groups)):\n",
        "            if metric == 'cosine':\n",
        "                dists = 1 - cosine_similarity(groups[i]).flatten()\n",
        "            else:\n",
        "                dists = squareform(pdist(groups[i], 'euclidean')).flatten()\n",
        "            data.append(dists[~np.isclose(dists, 0)])  # Remove self-comparisons\n",
        "\n",
        "        # Perform ANOVA\n",
        "        f_val, p_val = f_oneway(*data)\n",
        "        print(f\"\\n{metric.upper()} Distance:\")\n",
        "        print(f\"F-statistic: {f_val:.2f}, p-value: {p_val:.4f}\")\n",
        "\n",
        "        if p_val < 0.05:\n",
        "            # Post-hoc Tukey test\n",
        "            print(\"\\nPost-hoc Tukey HSD:\")\n",
        "            all_data = np.concatenate(data)\n",
        "            group_labels = np.concatenate([[f\"Group{group_names[i]}\"]*len(arr)\n",
        "                                         for i, arr in enumerate(data)])\n",
        "            tukey = pairwise_tukeyhsd(all_data, group_labels)\n",
        "            print(tukey)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality Reduction Visualization"
      ],
      "metadata": {
        "id": "Yx43A2UrFtnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn\n",
        "import umap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.manifold import trustworthiness\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "\n",
        "def analyze_and_visualize_embeddings(embeddings_list, group_names=('GroupA', 'GroupB', 'GroupC')):\n",
        "    \"\"\"\n",
        "    Perform dimensionality reduction and comparative analysis of multiple sets of embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        embeddings_list: List of embedding arrays [emb1, emb2, ...]\n",
        "        group_names: Tuple of group labels\n",
        "    \"\"\"\n",
        "    # Combine all embeddings and create group labels\n",
        "    combined = np.vstack(embeddings_list)\n",
        "    group_labels = np.concatenate([[name]*len(emb) for name, emb in zip(group_names, embeddings_list)])\n",
        "\n",
        "    # Color palette for visualization\n",
        "    palette = sns.color_palette(\"husl\", len(embeddings_list))\n",
        "    color_dict = {name: palette[i] for i, name in enumerate(group_names)}\n",
        "\n",
        "    # ============================================\n",
        "    # 1. PCA Dimensionality Reduction\n",
        "    # ============================================\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced_pca = pca.fit_transform(combined)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(x=reduced_pca[:, 0], y=reduced_pca[:, 1],\n",
        "                    hue=group_labels, palette=color_dict,\n",
        "                    alpha=0.7, s=50)\n",
        "    plt.title(\"PCA: Principal Component Analysis (2D Projection)\")\n",
        "    plt.xlabel(\"Principal Component 1\")\n",
        "    plt.ylabel(\"Principal Component 2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(title='Groups')\n",
        "    plt.show()\n",
        "\n",
        "    # PCA diagnostic metrics\n",
        "    explained_var = pca.explained_variance_ratio_\n",
        "    eigenvalues = pca.explained_variance_\n",
        "    projected = pca.inverse_transform(reduced_pca)\n",
        "    reconstruction_error = mean_squared_error(combined, projected)\n",
        "\n",
        "    print(\"PCA Diagnostic Metrics:\")\n",
        "    print(f\"- Eigenvalues: {eigenvalues}\")\n",
        "    print(f\"- Explained Variance Ratio: {explained_var}\")\n",
        "    print(f\"- Cumulative Explained Variance: {np.sum(explained_var):.4f}\")\n",
        "    print(f\"- Reconstruction MSE: {reconstruction_error:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    Eigenvalues indicate the magnitude of variance captured by each principal component.\n",
        "    Explained variance ratios show the proportion of total variance accounted for by each component.\n",
        "    Reconstruction error measures information loss during dimensionality reduction.\\n\"\"\")\n",
        "\n",
        "    # ============================================\n",
        "    # 2. t-SNE Visualization\n",
        "    # ============================================\n",
        "    tsne = TSNE(n_components=2, perplexity=30, random_state=42, init='pca')\n",
        "    reduced_tsne = tsne.fit_transform(combined)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(x=reduced_tsne[:, 0], y=reduced_tsne[:, 1],\n",
        "                    hue=group_labels, palette=color_dict,\n",
        "                    alpha=0.7, s=50)\n",
        "    plt.title(\"t-SNE: t-distributed Stochastic Neighbor Embedding\")\n",
        "    plt.xlabel(\"t-SNE Dimension 1\")\n",
        "    plt.ylabel(\"t-SNE Dimension 2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(title='Groups')\n",
        "    plt.show()\n",
        "\n",
        "    # t-SNE quality metrics\n",
        "    trust = trustworthiness(combined, reduced_tsne, n_neighbors=5)\n",
        "\n",
        "    # k-NN preservation calculation\n",
        "    knn_original = NearestNeighbors(n_neighbors=5).fit(combined).kneighbors(return_distance=False)\n",
        "    knn_embedded = NearestNeighbors(n_neighbors=5).fit(reduced_tsne).kneighbors(return_distance=False)\n",
        "    preserved = np.mean([\n",
        "        len(np.intersect1d(knn_original[i], knn_embedded[i])) / 5.0\n",
        "        for i in range(len(combined))\n",
        "    ])\n",
        "\n",
        "    print(\"t-SNE Quality Metrics:\")\n",
        "    print(f\"- KL Divergence: {tsne.kl_divergence_:.4f}\")\n",
        "    print(f\"- Trustworthiness: {trust:.4f}\")\n",
        "    print(f\"- k-NN Preservation Rate: {preserved:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    KL divergence quantifies the difference between high-dimensional and low-dimensional distributions.\n",
        "    Trustworthiness measures the preservation of neighborhood relationships (higher is better).\n",
        "    k-NN preservation rate indicates local structure maintenance during dimensionality reduction.\\n\"\"\")\n",
        "\n",
        "    # ============================================\n",
        "    # 3. UMAP Projection\n",
        "    # ============================================\n",
        "    reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, metric='euclidean', random_state=42)\n",
        "    reduced_umap = reducer.fit_transform(combined)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(x=reduced_umap[:, 0], y=reduced_umap[:, 1],\n",
        "                    hue=group_labels, palette=color_dict,\n",
        "                    alpha=0.7, s=50)\n",
        "    plt.title(\"UMAP: Uniform Manifold Approximation and Projection\")\n",
        "    plt.xlabel(\"UMAP Dimension 1\")\n",
        "    plt.ylabel(\"UMAP Dimension 2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(title='Groups')\n",
        "    plt.show()\n",
        "\n",
        "    # UMAP quality assessment\n",
        "    knn_embedded_umap = NearestNeighbors(n_neighbors=5).fit(reduced_umap).kneighbors(return_distance=False)\n",
        "    preserved_umap = np.mean([\n",
        "        len(np.intersect1d(knn_original[i], knn_embedded_umap[i])) / 5.0\n",
        "        for i in range(len(combined))\n",
        "    ])\n",
        "\n",
        "    print(\"UMAP Quality Metrics:\")\n",
        "    print(f\"- k-NN Preservation Rate: {preserved_umap:.4f}\")\n",
        "    print(\"\"\"Statistical Interpretation:\n",
        "    The k-NN preservation rate quantifies how well UMAP maintains local neighborhood structures\n",
        "    from the original high-dimensional space in the 2D projection.\\n\"\"\")\n",
        "\n",
        "    # ============================================\n",
        "    # 4. Pairwise Similarity Analysis\n",
        "    # ============================================\n",
        "    print(\"\\n=== Pairwise Similarity Analysis ===\")\n",
        "\n",
        "    # Create all possible group pairs\n",
        "    group_pairs = list(combinations(range(len(embeddings_list)), 2))\n",
        "\n",
        "    for i, j in group_pairs:\n",
        "        # Dot product analysis\n",
        "        dot_products = np.sum(embeddings_list[i] * embeddings_list[j], axis=1)\n",
        "        mean_dot = np.mean(dot_products)\n",
        "        std_dot = np.std(dot_products)\n",
        "\n",
        "        # Euclidean distance\n",
        "        euc_distances = np.linalg.norm(embeddings_list[i] - embeddings_list[j], axis=1)\n",
        "\n",
        "        # Plotting\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Dot product plot\n",
        "        sns.histplot(dot_products, bins=30, color=palette[i], alpha=0.7, ax=ax1)\n",
        "        ax1.axvline(mean_dot, color='red', linestyle='--', label=f\"Mean: {mean_dot:.4f}\")\n",
        "        ax1.set_title(f\"Dot Products: {group_names[i]} vs {group_names[j]}\")\n",
        "        ax1.set_xlabel(\"Dot Product Value\")\n",
        "        ax1.legend()\n",
        "\n",
        "        # Euclidean distance plot\n",
        "        sns.histplot(euc_distances, bins=30, color=palette[j], alpha=0.7, ax=ax2)\n",
        "        ax2.axvline(np.mean(euc_distances), color='red', linestyle='--',\n",
        "                    label=f\"Mean: {np.mean(euc_distances):.4f}\")\n",
        "        ax2.set_title(f\"Euclidean Distances: {group_names[i]} vs {group_names[j]}\")\n",
        "        ax2.set_xlabel(\"Distance\")\n",
        "        ax2.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\n{group_names[i]} vs {group_names[j]} Statistics:\")\n",
        "        print(f\"- Dot Product Mean ± Std: {mean_dot:.4f} ± {std_dot:.4f}\")\n",
        "        print(f\"- Euclidean Distance Mean ± Std: {np.mean(euc_distances):.4f} ± {np.std(euc_distances):.4f}\")\n",
        "        print(\"\"\"Statistical Interpretation:\n",
        "        Dot products measure vector alignment (higher = more similar).\n",
        "        Euclidean distances measure absolute separation (lower = more similar).\\n\"\"\")\n",
        "\n",
        "# Example usage with three groups\n",
        "embeddings_a = np.load(\"embeddings_a.npy\")\n",
        "embeddings_b = np.load(\"embeddings_b.npy\")\n",
        "embeddings_c = np.load(\"embeddings_c.npy\")\n",
        "\n",
        "analyze_and_visualize_embeddings([embeddings_a, embeddings_b, embeddings_c],\n",
        "                                group_names=('GroupA', 'GroupB', 'GroupC'))"
      ],
      "metadata": {
        "id": "OoQ-voreFs6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score data analysis"
      ],
      "metadata": {
        "id": "JlrzOiFDF3fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score, classification_report\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import MultiComparison\n",
        "\n",
        "# Load data\n",
        "df = pd.read_excel(\"/content/explicitextracted_scores_only.xlsx\")\n",
        "a_scores = df['group a score']\n",
        "b_scores = df['group b score']\n",
        "c_scores = df['group c score']\n",
        "\n",
        "# Descriptive Statistics\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(df[['group a score', 'group b score', 'group c score']].describe())\n",
        "\n",
        "# Pairwise Paired t-tests\n",
        "print(\"\\nPaired t-tests:\")\n",
        "for (x, y, label) in [(a_scores, b_scores, 'A vs B'), (a_scores, c_scores, 'A vs C'), (b_scores, c_scores, 'B vs C')]:\n",
        "    t_stat, p_val = ttest_rel(x, y)\n",
        "    print(f\"{label}: t = {t_stat:.4f}, p = {p_val:.4f} -> {'significant' if p_val < 0.05 else 'not significant'}\")\n",
        "\n",
        "# Boxplot and Density Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(data=df[['group a score', 'group b score', 'group c score']], palette=\"Set2\")\n",
        "plt.title(\"Boxplot of Scores\")\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(a_scores, label='Group A', fill=True)\n",
        "sns.kdeplot(b_scores, label='Group B', fill=True)\n",
        "sns.kdeplot(c_scores, label='Group C', fill=True)\n",
        "plt.title(\"Density Plot of Scores\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Repeated Measures ANOVA\n",
        "df_long = pd.melt(df[['group a score', 'group b score', 'group c score']],\n",
        "                  var_name='Group', value_name='Score')\n",
        "df_long['Subject'] = np.tile(np.arange(len(df)), 3)\n",
        "model = ols('Score ~ C(Group) + C(Subject)', data=df_long).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(\"\\nRepeated Measures ANOVA:\")\n",
        "print(anova_table)\n",
        "\n",
        "# Post-hoc test\n",
        "print(\"\\nPost-hoc Tukey HSD test:\")\n",
        "mc = MultiComparison(df_long['Score'], df_long['Group'])\n",
        "result = mc.tukeyhsd()\n",
        "print(result.summary())\n",
        "\n",
        "# Pairwise Scatterplots\n",
        "sns.pairplot(df[['group a score', 'group b score', 'group c score']])\n",
        "plt.suptitle(\"Pairwise Relationships Among Group Scores\", y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Difference Distributions\n",
        "df['b - a'] = b_scores - a_scores\n",
        "df['c - a'] = c_scores - a_scores\n",
        "df['c - b'] = c_scores - b_scores\n",
        "\n",
        "for col in ['b - a', 'c - a', 'c - b']:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.axvline(0, color='red', linestyle='--')\n",
        "    plt.title(f\"Distribution of Score Differences ({col.upper()})\")\n",
        "    plt.xlabel(\"Score Difference\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Cohen's Kappa Analysis\n",
        "bins = [1.9, 2.25, 2.75, 3.25, 3.75, 4.25, 4.75]\n",
        "labels = ['2', '2.5', '3', '3.5', '4', '4.5']\n",
        "\n",
        "a_cat = pd.cut(a_scores, bins=bins, labels=labels, right=False)\n",
        "b_cat = pd.cut(b_scores, bins=bins, labels=labels, right=False)\n",
        "c_cat = pd.cut(c_scores, bins=bins, labels=labels, right=False)\n",
        "\n",
        "for (true, pred, label) in [(a_cat, b_cat, \"A vs B\"), (a_cat, c_cat, \"A vs C\"), (b_cat, c_cat, \"B vs C\")]:\n",
        "    print(f\"\\nCohen’s Kappa Score for {label}:\")\n",
        "    kappa = cohen_kappa_score(true, pred)\n",
        "    print(f\"  Score: {kappa:.3f}\")\n",
        "    level = (\"Almost no consistency\" if kappa < 0.2 else\n",
        "             \"Less consistency\" if kappa < 0.4 else\n",
        "             \"Medium consistency\" if kappa < 0.6 else\n",
        "             \"Good consistency\" if kappa < 0.8 else\n",
        "             \"Almost perfect consistency\")\n",
        "    print(f\"  → Consistency level: {level}\")\n",
        "\n",
        "    conf_mat = confusion_matrix(true, pred, labels=labels)\n",
        "    disp = ConfusionMatrixDisplay(conf_mat, display_labels=labels)\n",
        "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "    plt.title(f\"Confusion Matrix ({label})\")\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true, pred, target_names=labels, zero_division=0))\n",
        "\n",
        "# Change Direction\n",
        "for label, diff_col in [('B vs A', 'b - a'), ('C vs A', 'c - a'), ('C vs B', 'c - b')]:\n",
        "    df['direction'] = np.where(df[diff_col] > 0, 'Increase',\n",
        "                            np.where(df[diff_col] < 0, 'Decrease', 'No change'))\n",
        "    direction_counts = df['direction'].value_counts()\n",
        "    print(f\"\\nScore change direction for {label}:\")\n",
        "    print(direction_counts)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(x=direction_counts.index, y=direction_counts.values, palette=\"viridis\")\n",
        "    plt.title(f\"Score Change Direction: {label}\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "# Per-score level difference\n",
        "print(\"\\nAnalysis of variances by specific Group A scores:\")\n",
        "score_levels = sorted(df['group a score'].unique())\n",
        "for score in score_levels:\n",
        "    subset = df[df['group a score'] == score]\n",
        "    for label, col in [('Group B', 'group b score'), ('Group C', 'group c score')]:\n",
        "        mean_diff = (subset[col] - subset['group a score']).mean()\n",
        "        count = len(subset)\n",
        "        print(f\"When Group A is {score:.1f}（n={count}）, {label} avg diff: {mean_diff:.3f}\")\n",
        "\n",
        "# KDE per score level\n",
        "for diff_col in ['b - a', 'c - a', 'c - b']:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for score in sorted(df['group a score'].unique()):\n",
        "        subset = df[df['group a score'] == score]\n",
        "        sns.kdeplot(subset[diff_col], label=f'A={score}', fill=True)\n",
        "    plt.axvline(0, color='red', linestyle='--')\n",
        "    plt.title(f\"Distribution of {diff_col.upper()} by Group A Score\")\n",
        "    plt.xlabel(\"Score Difference\")\n",
        "    plt.legend(title=\"Group A Score\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Overall mean difference\n",
        "print(\"\\nAverage Score Differences:\")\n",
        "for label, col in [('B - A', 'b - a'), ('C - A', 'c - a'), ('C - B', 'c - b')]:\n",
        "    print(f\"{label}: {df[col].mean():.3f}\")"
      ],
      "metadata": {
        "id": "NCeQ2QBTF7II"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}